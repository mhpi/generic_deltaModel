{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: **δHBV 2.0**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates forward simulation with the pre-trained model δHBV 2.0UH developed by [Yalan Song et al. (2025)](https://doi.org/10.1029/2024WR038928). For explanation of model structure, methodologies, [data](https://mhpi.github.io/datasets/CONUS/#results), and performance metrics, please refer to Song's publication [below](#publication). If you find this code is useful in your own work, please include the aforementioned citation.\n",
    "\n",
    "**Note**: If you are new to the dMG framework, we suggest first looking at our [δHBV 1.0 tutorial](./../hydrology/example_dhbv_1_0.ipynb).\n",
    "\n",
    "<br>\n",
    "\n",
    "### Before Running:\n",
    "- **Environment**: See [setup.md](./../../docs/setup.md) for ENV setup. dMG must be installed with dependencies + hydroDL2 to run this notebook.\n",
    "\n",
    "- **Model and Data**: The pretrained δHBV 2.0 model weights + input data can be downloaded from [sharepoint](https://pennstateoffice365-my.sharepoint.com/:f:/g/personal/cxs1024_psu_edu/Eqi1NuJ3d2pMpEJpVu0EGSoBigi-VCWVHgOYIRoTeuGiOw?e=HaNNeA). After downloading, update model and data key paths in their respective configs:\n",
    "\n",
    "    1. In [`./generic_deltamodel/example/conf/config_dhbv_2_0.yaml`](./../conf/config_dhbv_2_0.yaml), update *trained_model* with your path to the parent directory containing both trained model weights `dHBV_2_0_Ep100.pt` **and** normalization file `normalization_statistics.json`.\n",
    "\n",
    "    2. In [`./generic_deltamodel/example/conf/observations/merit.yaml`](./../conf/observations/merit.yaml), update *subbasin_data_path* with your path to `./merit_71_0/`.\n",
    "\n",
    "- **Hardware**: The NNs used in this model require CUDA support only available with Nvidia GPUs. For those without access, T4 GPUs can be used when running this notebook with dMG on [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "### Publication:\n",
    "*Yalan Song, Tadd Bindas, Chaopeng Shen, Haoyu Ji, Wouter Johannes Maria Knoben, Leo Lonzarich, Martyn P. Clark, et al. \"High-resolution national-scale water modeling is enhanced by multiscale differentiable physics-informed machine learning.\" Water Resources Research (2025). https://doi.org/10.1029/2024WR038928.*\n",
    "\n",
    "<br>\n",
    "\n",
    "### Issues:\n",
    "For questions, concerns, bugs, etc., please reach out by posting an [issue](https://github.com/mhpi/generic_deltaModel/issues) on GitHub.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Forward δHBV 2.0\n",
    "\n",
    "After completing [these](#before-running) steps, forward δHBV 2.0 with the code block below.\n",
    "\n",
    "**Note**\n",
    "- The settings defined in the config file `../example/conf/config_dhbv_2_0.yaml` are set to replecate benchmark performance.\n",
    "- For model evaluation, set `mode: predict` in the config, or modify after the config dict has been created (see below).\n",
    "- The first year (`warm_up` in the config, 365 days is default) of the inference period is used for initializing HBV's internal states (water storages) and is, therefore, excluded from the model's prediction output.\n",
    "- For default settings with the inference window set from 1 January 1980 to 31 December 2020, expect ~70GB of vram utilization and a runtime of ~1 minute. (Vram use can be reduced by increasing `predict` batchsize in the model config.)\n",
    "\n",
    "### 1.1 Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from dMG.core.utils import print_config, import_data_loader, set_randomseed, import_trainer\n",
    "from example import load_config\n",
    "from dMG import ModelHandler\n",
    "\n",
    "#------------------------------------------#\n",
    "# Define model settings here.\n",
    "CONFIG_PATH = '../example/conf/config_dhbv_2_0.yaml'\n",
    "#------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Load configuration dictionary of model parameters and options.\n",
    "config = load_config(CONFIG_PATH)\n",
    "config['mode'] = 'predict'\n",
    "print_config(config)\n",
    "\n",
    "# Set random seed for reproducibility.\n",
    "set_randomseed(config['random_seed'])\n",
    "\n",
    "# 2. Initialize the differentiable HBV 1.1p model (LSTM + HBV 1.1p).\n",
    "model = ModelHandler(config, verbose=True)\n",
    "\n",
    "# 3. Load and initialize a dataset dictionary of NN and HBV model inputs.\n",
    "data_loader_cls = import_data_loader(config['data_loader'])\n",
    "data_loader = data_loader_cls(config, test_split=False, overwrite=False)\n",
    "\n",
    "# 4. Initialize trainer to handle forward pass.\n",
    "trainer_cls = import_trainer(config['trainer'])\n",
    "trainer = trainer_cls(\n",
    "    config,\n",
    "    model,\n",
    "    inf_dataset=data_loader.dataset,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 5. Forward pass through the model to get streamflow predictions.\n",
    "predictions = trainer.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing Model Predictions\n",
    "\n",
    "After running model inference we can, e.g., view the hydrograph for one of the basins to see we are getting expected outputs.\n",
    "\n",
    "We can do this with our target variable, streamflow, for instance (though, there are many other states and fluxes we can view -- see cell output below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from dMG.core.data import txt_to_array\n",
    "from dMG.core.post import plot_hydrograph\n",
    "from dMG.core.utils import Dates\n",
    "\n",
    "#------------------------------------------#\n",
    "# Choose a catchment by unit catchment ID (COMID) to plot.\n",
    "COMID = 71024425\n",
    "TARGET = 'streamflow'\n",
    "\n",
    "# Resample to 3-day prediction. Options: 'D', 'W', 'M', 'Y'.\n",
    "RESAMPLE = 'D'\n",
    "\n",
    "# Set the path to the zarr store of input data (containing COMIDs).\n",
    "DATA_PATH = './your/path/to/MERIT_input_sample/71_0'\n",
    "#------------------------------------------#\n",
    "\n",
    "\n",
    "# 1. Get the streamflow predictions and daily timesteps of the prediction window.\n",
    "print(f\"HBV states and fluxes: {predictions.keys()} \\n\")\n",
    "\n",
    "pred = predictions[TARGET]\n",
    "timesteps = Dates(config['predict'], config['dpl_model']['rho']).batch_daily_time_range\n",
    "\n",
    "# Remove warm-up period to match model output (see Note above.)\n",
    "timesteps = timesteps[config['dpl_model']['phy_model']['warm_up']:]\n",
    "\n",
    "\n",
    "# 2. Load array of comids and get the index of the selected catchment.\n",
    "root = zarr.open_group(DATA_PATH, mode='r+')\n",
    "comids = root['COMID'][:]\n",
    "print(f\"First 20 available COMIDs: \\n {comids[:20]} \\n\")\n",
    "\n",
    "if COMID in comids:\n",
    "    basin_idx = list(comids).index(COMID)\n",
    "else:\n",
    "    raise ValueError(f\"Catchment with ID {COMID} not found in the MERIT dataset.\")\n",
    "\n",
    "\n",
    "# 3. Get the data for the chosen catchment and plot.\n",
    "streamflow_pred_basin = pred[:, basin_idx].squeeze()\n",
    "\n",
    "plot_hydrograph(\n",
    "    timesteps,\n",
    "    streamflow_pred_basin,\n",
    "    resample=RESAMPLE,\n",
    "    title=f\"Hydrograph for Catchment {COMID}\",\n",
    "    ylabel='Streamflow (ft$^3$/s)',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Train/Evaluate $\\delta$ HBV 2.0\n",
    "\n",
    "*Multiscale training for dHBV2.0 is not currently enabled in dMG. Training code will be released at a later time.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
