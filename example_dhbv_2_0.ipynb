{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: **$\\delta$ HBV 2.0**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates how to forward a pre-trained $\\delta$ HBV 2.0UH model developed by [Yalan Song et al. (2024)](https://doi.org/10.22541/essoar.172736277.74497104/v1). For explanation of model structure, methodologies, [data](https://mhpi.github.io/datasets/CONUS/#results), and performance metrics, please refer to Song's publication [below](#publication). If you find this code is useful in your own work, please include the aforementioned citation.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Before Running:\n",
    "- **Environment**: From `env/` a minimal Python environment can be setup for running this code... (see `docs/getting_started.md` for more details.)\n",
    "    - Conda -- `deltamodel_env.yaml`\n",
    "    - Pip -- `requirements.txt`\n",
    "\n",
    "\n",
    "- **Model and Data**: The trained $\\delta$ HBV 2.0 model and input data can be downloaded from [sharepoint](https://pennstateoffice365-my.sharepoint.com/:f:/g/personal/cxs1024_psu_edu/Eqi1NuJ3d2pMpEJpVu0EGSoBigi-VCWVHgOYIRoTeuGiOw?e=HaNNeA). After downloading...\n",
    "\n",
    "    1. Update the `subbasin_data_path` key in data config `example/conf/observations/merit_forward.yaml` with your path to `MERIT_input_sample/71_0`.\n",
    "\n",
    "    2. Update the `trained_model` key in model config `example/conf/config_dhbv_2_0.yaml` with the path to you directory containing the trained model `dHBV_2_0_Ep100.pt` AND normalization `test1980-2020_Ep100/normalization_statistics.json`.\n",
    "\n",
    "- **Hardware**: The LSTMs used in this model require CUDA support only available with Nvidia GPUs. For those without access, T4 GPUs can be used when running this notebook with dMG on [Google Colab](https://colab.research.google.com/).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Publication:\n",
    "\n",
    "*Song, Yalan, Tadd Bindas, Chaopeng Shen, Haoyu Ji, Wouter Johannes Maria Knoben, Leo Lonzarich, Martyn P. Clark et al. \"High-resolution national-scale water modeling is enhanced by multiscale differentiable physics-informed machine learning.\" Authorea Preprints (2024). https://essopenarchive.org/doi/full/10.22541/essoar.172736277.74497104.*\n",
    "\n",
    "<br>\n",
    "\n",
    "### Issues:\n",
    "For questions, concerns, bugs, etc., please reach out by posting an issue on the [dMG repo](https://github.com/mhpi/generic_deltaModel/issues).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Train/Evaluate $\\delta$ HBV 2.0\n",
    "\n",
    "*Multiscale training for dHBV2.0 is not currently enabled in dMG. Training code will be released at a later time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Forward $\\delta$ HBV 2.0\n",
    "\n",
    "After completing [these](#before-running) steps, forward the $\\delta$ HBV 2.0 model with the code block below.\n",
    "\n",
    "--> For default settings expect evaluation time of ~1 minute with an Nvidia A100.\n",
    "\n",
    "**Note**\n",
    "- The settings defined in the config file `../example/conf/config_dhbv_2_0.yaml` are set to replecate benchmark performance.\n",
    "- For model evaluation, set `mode: predict` in the config, or modify after the config dict has been created (see below).\n",
    "- The default inference window is set from 1 January 1980 to 31 December 2020, which should use ~70GB of vram.\n",
    "- The first year (`warm_up` in the config, 365 days is default) of the inference period is used for initializing HBV's internal states (water storages) and is, therefore, excluded from the model's prediction output.\n",
    "- If you are new to the *dMG* framework and want further explanation and exposure of the methods used below, we suggest first looking at our notebook for $\\delta$ HBV 1.0: `example/hydrology/example_dhbv_1_0.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../dMG')  # Add the dMG root directory.\n",
    "\n",
    "from example import load_config \n",
    "from models.model_handler import ModelHandler as dHBV\n",
    "from core.utils import print_config\n",
    "from core.utils.factory import import_data_loader, import_trainer\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------#\n",
    "# Define model settings here.\n",
    "CONFIG_PATH = '../example/conf/config_dhbv_2_0.yaml'\n",
    "#------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load configuration dictionary of model parameters and options.\n",
    "config = load_config(CONFIG_PATH)\n",
    "print_config(config)\n",
    "\n",
    "# 2. Setup a dataset loader to prepare NN and physics model inputs.\n",
    "data_loader_cls = import_data_loader(config['data_loader'])\n",
    "data_loader = data_loader_cls(config, test_split=True, overwrite=False)\n",
    "\n",
    "# 3. Initialize the differentiable model dHBV 2.0 (LSTM + HBV 2.0).\n",
    "model = dHBV(config, verbose=True)\n",
    "\n",
    "# 4. Initialize trainer to handle forward pass.\n",
    "trainer_cls = import_trainer(config['trainer'])\n",
    "trainer = trainer_cls(\n",
    "    config,\n",
    "    model,\n",
    "    inf_dataset=data_loader.dataset,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 5. Forward pass through the model to get streamflow predictions.\n",
    "predictions = trainer.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Model Predictions\n",
    "\n",
    "After running model inference we can, e.g., view the hydrograph for one of the catchments to see we are getting expected outputs.\n",
    "\n",
    "We can do this with our target variable, streamflow, for instance... (though, there are many other states and fluxes we can output as shown in the output cell below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "from core.utils.dates import Dates\n",
    "from core.post.plot_hydrograph import plot_hydrograph\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------#\n",
    "# Choose a catchment by unit catchment ID (COMID) to plot.\n",
    "COMID = 71024425\n",
    "TARGET = 'flow_sim'\n",
    "\n",
    "# Resample to 3-day prediction. Options: 'D', 'W', 'M', 'Y'.\n",
    "RESAMPLE = 'D'\n",
    "\n",
    "# Set the path to the zarr store of input data (containing COMIDs).\n",
    "DATA_PATH = 'your/path/to/MERIT_input_sample/71_0'\n",
    "#------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "print(f\"HBV states and fluxes: {predictions.keys()} \\n\")\n",
    "\n",
    "\n",
    "# 1. Get the streamflow predictions and daily timesteps of the prediction window.\n",
    "pred = predictions[TARGET]\n",
    "timesteps = Dates(config['predict'], config['dpl_model']['rho']).batch_daily_time_range\n",
    "\n",
    "# Remove warm-up period to match model output (see Note above.)\n",
    "timesteps = timesteps[config['dpl_model']['phy_model']['warm_up']:]\n",
    "\n",
    "\n",
    "# 2. Load array of comids and get the index of the selected catchment.\n",
    "root = zarr.open_group(DATA_PATH, mode='r+')\n",
    "comids = root['COMID'][:]\n",
    "print(f\"First 20 available COMIDs: \\n {comids[:20]} \\n\")\n",
    "\n",
    "if COMID in comids:\n",
    "    basin_idx = list(comids).index(COMID)\n",
    "else:\n",
    "    raise ValueError(f\"Catchment with ID {COMID} not found in the MERIT dataset.\")\n",
    "\n",
    "\n",
    "# 3. Get the data for the chosen catchment and plot.\n",
    "streamflow_pred_basin = pred[:, basin_idx].squeeze()\n",
    "\n",
    "plot_hydrograph(\n",
    "    timesteps,\n",
    "    streamflow_pred_basin,\n",
    "    streamflow_pred_basin,\n",
    "    resample=RESAMPLE,\n",
    "    title=f\"Hydrograph for Catchment {COMID}\",\n",
    "    ylabel='Streamflow (ft$^3$/s)',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
